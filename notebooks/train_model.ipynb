{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements autoencoder trial run cycles.\n",
    "\n",
    "* Define\n",
    "    * trial name\n",
    "    * environment to work with (MyBallsEnv, MyArmEnv, GymArmEnv)\n",
    "    * dataset to use (set of 3 npz files for train, test and grid visualization, each file contains many angle/image pairs)\n",
    "    * model builder\n",
    "    * list of parameters to try\n",
    "    * number of epochs to run \n",
    "    * output directory\n",
    "* Run\n",
    "    * fails if output directory exists, otherwise creates it\n",
    "    * chooses a set of model parameters\n",
    "Thursday 4/03/2021\n",
    "\n",
    "* Visualize YYs (third output sheet or animated GIF) to assess decoder performance\n",
    "* Rerun with [2, 10, 50] epochs\n",
    "* Implement beta-VAE (see beta-vae notebook)\n",
    "\n",
    "Next:\n",
    "\n",
    "* Explore impact of changing filters chain down to 2x (2,2)\n",
    "* Scatterplot 3D\n",
    "* How does it fluctuate depending on network architecture, nlats, training protocol, etc\n",
    "* Explore fold area in L0/L1 space. For each frame show:\n",
    " * image of gym robot,\n",
    " * colored L0/L1 scatterplot, with a red cross showing current latent state,\n",
    " * image reconstructed by the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoMQk_5c4UYm",
    "outputId": "02cc896f-38e0-4a92-81ce-c20a7322369d"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.config import output_data_dir\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_autoencoder(ae, dataset, prefix=\"\", N=10, vae=False):\n",
    "    Y = dataset['images']\n",
    "    \n",
    "    L = ae['enc'].predict(Y)\n",
    "    L = np.array(L)\n",
    "\n",
    "    if vae:\n",
    "        L = np.array(L)[2] # [z_mean, z_log_var, z] - take Z\n",
    "\n",
    "    YY = ae['dec'].predict(L)\n",
    "    YY = np.array(YY)\n",
    "    \n",
    "    out_data = dict()\n",
    "    out_data['latvars'] = L\n",
    "    out_data['rec_images'] = YY\n",
    "\n",
    "    return out_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.vae\n",
    "\n",
    "# define ae builder method and environment name\n",
    "ae_builder = src.models.vae.build_autoencoder\n",
    "ENV_NAME = \"twoballs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_DIR = os.path.join(output_data_dir, ENV_NAME) # FUXNE\n",
    "\n",
    "# fail if TRIAL_DIR exists\n",
    "assert(not os.path.exists(TRIAL_DIR))\n",
    "    \n",
    "# create trial subdirs\n",
    "TENSORBOARD_LOGS_DIR =  \"%s/tensorboard-logs\" % TRIAL_DIR\n",
    "TRAINED_MODELS_DIR = \"%s/trained-models\" % TRIAL_DIR\n",
    "#DATA_DIR = \"%s/data\" % TRIAL_DIR\n",
    "IMGS_DIR = \"%s/imgs\" % TRIAL_DIR\n",
    "\n",
    "#for dir in [TENSORBOARD_LOGS_DIR, TRAINED_MODELS_DIR, DATA_DIR, IMGS_DIR]:\n",
    "for dir in [TENSORBOARD_LOGS_DIR, TRAINED_MODELS_DIR, IMGS_DIR]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.data.dataset import load_datasets\n",
    "\n",
    "datasets = load_datasets(ENV_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.models import save_models, save_models_weights\n",
    "from src.visualization.lat import visualize_lat_space, animate_Y_YYs\n",
    "\n",
    "def save_visualization(dataset, dataset_grid_out, round, epoch):\n",
    "    vis_fname = \"%s/round-%d_epoch-%d.png\" % (IMGS_DIR, round, epoch)\n",
    "    ani_fname = \"%s/round-%d_epoch-%d.mp4\" % (IMGS_DIR, round, epoch)\n",
    "\n",
    "    # save 4x4 visualization of pairwise plots of latvars vs angles\n",
    "    fig, axs = visualize_lat_space(dataset['grid'], dataset_grid_out, sheet=1)\n",
    "    fig.savefig(vis_fname)\n",
    "    \n",
    "    #vis_fname2 = \"%s/%sb.png\" % (IMGS_DIR, suffix)\n",
    "    #fig, axs = visualize_lat_space(dataset['grid'], dataset_grid_out, sheet=2)\n",
    "    #fig.savefig(vis_fname2)\n",
    "\n",
    "    # save MP4\n",
    "    NANIFRAMES = 20\n",
    "    logger.debug(\"saving ani visualization (for %d datapoints from grid dataset) into %s\" % (NANIFRAMES, ani_fname))\n",
    "    rng = np.random.default_rng()\n",
    "    ani_is = rng.choice(range(dataset['grid']['images'].shape[0]), size=NANIFRAMES) # choose 20 random items from the dataset_grid\n",
    "    animate_Y_YYs(dataset['grid']['images'][ani_is], dataset_grid_out['rec_images'][ani_is], outfile=ani_fname)\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "def run_round(datasets, ae_builder, params, round):\n",
    "    #if os.path.isfile(latvars_fname):\n",
    "    #    logger.error(\"%s exists, skipping ...\" % latvars_fname)\n",
    "    #    return\n",
    "    \n",
    "    print(\"*** run_round(%d, %s)\" % (round, str(params)))\n",
    "       \n",
    "    models = ae_builder((64, 64, 1), 2, params)\n",
    "\n",
    "    tensorboard_logdir = os.path.join((\"%s/round-%d\" % (TENSORBOARD_LOGS_DIR, round)),\n",
    "                                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(tensorboard_logdir) #, histogram_freq=1)\n",
    "\n",
    "    for epoch in range(params['epochs']):\n",
    "        logger.info(\"round-%d_epoch-%d: fit\" % (round, epoch))\n",
    "        models['ae'].fit(datasets['train']['images'], callbacks=[tensorboard_callback],\n",
    "               initial_epoch=epoch, epochs=epoch+1, batch_size=128)\n",
    "        save_models_weights(models, \"%s/round-%d_epoch-%d\" % (TRAINED_MODELS_DIR, round, epoch))\n",
    "\n",
    "        logger.info(\"round-%d_epoch-%d: cycle\" % (round, epoch))\n",
    "        dataset_grid_out = cycle_autoencoder(models, datasets['grid'], vae=True)\n",
    "        save_visualization(datasets, dataset_grid_out, round, epoch)\n",
    "    \n",
    "        # save angles & latvars for grid dataset\n",
    "        dataset_test_out = cycle_autoencoder(models, datasets['test'], vae=True)\n",
    "        latvars_fname = \"%s/round-%d_epoch-%d.csv\" % (IMGS_DIR, round, epoch)\n",
    "        angles_latvars = np.hstack((datasets['test']['angles'], dataset_test_out['latvars']))\n",
    "        np.savetxt(latvars_fname, angles_latvars, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "for round in range(10):\n",
    "    run_round(datasets, ae_builder, {'epochs': 100}, round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir ..\\data\\output\\twoballs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "robot-arm-vae2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
