{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements autoencoder trial run cycles.\n",
    "\n",
    "* Define\n",
    "    * trial name\n",
    "    * environment to work with (MyBallsEnv, MyArmEnv, GymArmEnv)\n",
    "    * dataset to use (set of 3 npz files for train, test and grid visualization, each file contains many angle/image pairs)\n",
    "    * model builder\n",
    "    * list of parameters to try\n",
    "    * number of epochs to run \n",
    "    * output directory\n",
    "* Run\n",
    "    * fails if output directory exists, otherwise creates it\n",
    "    * chooses a set of model parameters\n",
    "Thursday 4/03/2021\n",
    "\n",
    "* Visualize YYs (third output sheet or animated GIF) to assess decoder performance\n",
    "* Rerun with [2, 10, 50] epochs\n",
    "* Implement beta-VAE (see beta-vae notebook)\n",
    "\n",
    "Next:\n",
    "\n",
    "* Explore impact of changing filters chain down to 2x (2,2)\n",
    "* Scatterplot 3D\n",
    "* How does it fluctuate depending on network architecture, nlats, training protocol, etc\n",
    "* Explore fold area in L0/L1 space. For each frame show:\n",
    " * image of gym robot,\n",
    " * colored L0/L1 scatterplot, with a red cross showing current latent state,\n",
    " * image reconstructed by the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoMQk_5c4UYm",
    "outputId": "02cc896f-38e0-4a92-81ce-c20a7322369d"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.config import output_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models, datasets, params, tensorboard_logdir):\n",
    "    ae = models['ae']\n",
    "    \n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(tensorboard_logdir) #, histogram_freq=1)\n",
    "    \n",
    "    # FIXME ae.fit(dataset['Y'], validation_data=(val_dataset['Y'], val_dataset['Y']), callbacks=[tensorboard_callback],\n",
    "    ae.fit(datasets['train']['images'], callbacks=[tensorboard_callback],\n",
    "        epochs=params['epochs'], batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_autoencoder(ae, dataset, prefix=\"\", N=10, vae=False, display=False):\n",
    "    Y = dataset['images']\n",
    "    \n",
    "    if display:\n",
    "        print(\"Y.shape=\" + str(Y.shape))\n",
    "    L = ae['enc'].predict(Y)\n",
    "    L = np.array(L)\n",
    "    if display:\n",
    "        print(\"L.shape=\" + str(L.shape))\n",
    "\n",
    "    if vae:\n",
    "        L = np.array(L)[2] # [z_mean, z_log_var, z] - take Z\n",
    "\n",
    "    YY = ae['dec'].predict(L)\n",
    "    YY = np.array(YY)\n",
    "    if display:\n",
    "        print(\"YY.shape=\" + str(YY.shape))\n",
    "    \n",
    "    out_data = dict()\n",
    "    out_data['latvars'] = L\n",
    "    out_data['rec_images'] = YY\n",
    "\n",
    "    # - Y\n",
    "    if display:\n",
    "        plot_Ys(Y[0:N,...], title=\"First %d elements of %sY\" % (N, prefix))\n",
    "\n",
    "        # - L\n",
    "        fig, axs = plt.subplots(1, L.shape[1])\n",
    "        fig.suptitle(\"Latent variables %s\" % (str(L.shape)))\n",
    "        for i in range(L.shape[1]):\n",
    "            axs[i].hist(L[:,i])    \n",
    "\n",
    "        # - YY\n",
    "        plot_Ys(YY[0:N,...], title=\"First %d elements of %sYY\" % (N, prefix))\n",
    "\n",
    "        display_xvars(data)\n",
    "    \n",
    "    return out_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.models import save_models, save_models_weights\n",
    "from src.visualization.lat import visualize_lat_space, animate_Y_YYs\n",
    "\n",
    "def trial(dataset, ae_builder, params, suffix):\n",
    "    print(\"*** trial(%s, %s)\" % (str(params), suffix))\n",
    "    \n",
    "    vis_fname = \"%s/%sa.png\" % (IMGS_DIR, suffix)\n",
    "    vis_fname2 = \"%s/%sb.png\" % (IMGS_DIR, suffix)\n",
    "    ani_fname = \"%s/%s.mp4\" % (IMGS_DIR, suffix)\n",
    "    \n",
    "    if os.path.isfile(vis_fname):\n",
    "        print(\"%s exists, skipping ...\" % vis_fname)\n",
    "        return\n",
    "    \n",
    "    print(\"training AE, build_params=%s\" % str(params))\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    ae_models = ae_builder((64, 64, 1), 2, params)\n",
    "\n",
    "    tensorboard_logdir = os.path.join((\"%s/%s\" % (TENSORBOARD_LOGS_DIR, suffix)),\n",
    "                                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    train_models(ae_models, dataset, params, tensorboard_logdir)\n",
    "\n",
    "    save_models_weights(ae_models, \"%s/%s\" % (TRAINED_MODELS_DIR, suffix))\n",
    "    \n",
    "    print(\"running AE on grid dataset, saving visualization into %s\" % (vis_fname))    \n",
    "    dataset_grid_out = cycle_autoencoder(ae_models, dataset['grid'], vae=True, display=False)\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset['grid'], dataset_grid_out, sheet=1)\n",
    "    fig.savefig(vis_fname)\n",
    "    fig.clf() # FIXME - not helping, figures still exist and slow things down\n",
    "    \n",
    "    fig, axs = visualize_lat_space(dataset['grid'], dataset_grid_out, sheet=2)\n",
    "    fig.savefig(vis_fname2)\n",
    "    fig.clf() # FIXME - not helping, figures still exist and slow things down\n",
    "\n",
    "    NANIFRAMES = 20\n",
    "    print(\"saving ani visualization (for %d datapoints from grid dataset) into %s\" % (NANIFRAMES, ani_fname))\n",
    "    rng = np.random.default_rng()\n",
    "    ani_is = rng.choice(range(dataset['grid']['images'].shape[0]), size=NANIFRAMES) # choose 20 random items from the dataset_grid\n",
    "    animate_Y_YYs(dataset['grid']['images'][ani_is], dataset_grid_out['rec_images'][ani_is], outfile=ani_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.vae\n",
    "\n",
    "# define ae builder method and environment name\n",
    "ae_builder = src.models.vae.build_autoencoder\n",
    "ENV_NAME = \"twoballs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_DIR = os.path.join(output_data_dir, ENV_NAME) # FUXNE\n",
    "\n",
    "# fail if TRIAL_DIR exists\n",
    "assert(not os.path.exists(TRIAL_DIR))\n",
    "    \n",
    "# create trial subdirs\n",
    "TENSORBOARD_LOGS_DIR =  \"%s/tensorboard-logs\" % TRIAL_DIR\n",
    "TRAINED_MODELS_DIR = \"%s/trained-models\" % TRIAL_DIR\n",
    "DATA_DIR = \"%s/data\" % TRIAL_DIR\n",
    "IMGS_DIR = \"%s/imgs\" % TRIAL_DIR\n",
    "\n",
    "for dir in [TENSORBOARD_LOGS_DIR, TRAINED_MODELS_DIR, DATA_DIR, IMGS_DIR]:\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:39:24,698 - src.data.dataset - INFO - Loading C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_linspaced_100.npz ...\n",
      "2021-03-06 17:39:25,056 - src.data.dataset - INFO - Loaded 10000 datapoints from C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_linspaced_100.npz\n",
      "2021-03-06 17:39:25,057 - src.data.dataset - INFO - Loading C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_rand_1000.npz ...\n",
      "2021-03-06 17:39:25,130 - src.data.dataset - INFO - Loaded 1000 datapoints from C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_rand_1000.npz\n",
      "2021-03-06 17:39:25,131 - src.data.dataset - INFO - Loading C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_grid_100_1000.npz ...\n",
      "2021-03-06 17:39:31,744 - src.data.dataset - INFO - Loaded 100000 datapoints from C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\processed\\twoballs_grid_100_1000.npz\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataset import load_datasets\n",
    "\n",
    "dataset = load_datasets(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** trial({'epochs': 50}, epochs_50-0)\n",
      "training AE, build_params={'epochs': 50}\n",
      "Models weights saved to C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/trained-models/epochs_50-0 ...\n",
      "running AE on grid dataset, saving visualization into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-0a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:53:10,242 - matplotlib.animation - INFO - Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
      "2021-03-06 17:53:10,246 - matplotlib.animation - INFO - MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 288x144 -pix_fmt rgba -r 5.0 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-0.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ani visualization (for 20 datapoints from grid dataset) into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-0.mp4\n",
      "*** trial({'epochs': 50}, epochs_50-1)\n",
      "training AE, build_params={'epochs': 50}\n",
      "Models weights saved to C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/trained-models/epochs_50-1 ...\n",
      "running AE on grid dataset, saving visualization into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-1a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:55:47,980 - matplotlib.animation - INFO - Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
      "2021-03-06 17:55:47,984 - matplotlib.animation - INFO - MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 288x144 -pix_fmt rgba -r 5.0 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-1.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ani visualization (for 20 datapoints from grid dataset) into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-1.mp4\n",
      "*** trial({'epochs': 50}, epochs_50-2)\n",
      "training AE, build_params={'epochs': 50}\n",
      "Models weights saved to C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/trained-models/epochs_50-2 ...\n",
      "running AE on grid dataset, saving visualization into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-2a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:58:21,982 - matplotlib.animation - INFO - Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
      "2021-03-06 17:58:21,988 - matplotlib.animation - INFO - MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 288x144 -pix_fmt rgba -r 5.0 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-2.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ani visualization (for 20 datapoints from grid dataset) into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-2.mp4\n",
      "*** trial({'epochs': 50}, epochs_50-3)\n",
      "training AE, build_params={'epochs': 50}\n",
      "Models weights saved to C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/trained-models/epochs_50-3 ...\n",
      "running AE on grid dataset, saving visualization into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-3a.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 18:00:58,855 - matplotlib.animation - INFO - Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
      "2021-03-06 18:00:58,860 - matplotlib.animation - INFO - MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 288x144 -pix_fmt rgba -r 5.0 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-3.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ani visualization (for 20 datapoints from grid dataset) into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-3.mp4\n",
      "*** trial({'epochs': 50}, epochs_50-4)\n",
      "training AE, build_params={'epochs': 50}\n",
      "Models weights saved to C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/trained-models/epochs_50-4 ...\n",
      "running AE on grid dataset, saving visualization into C:\\Users\\alexa\\Documents\\dvp\\autoenc2\\data\\output\\twoballs/imgs/epochs_50-4a.png\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-6735ded37d49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0moutput_suffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"epochs_%d-%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mae_builder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_suffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-a6963378c3ab>\u001b[0m in \u001b[0;36mtrial\u001b[1;34m(dataset, ae_builder, params, suffix)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"running AE on grid dataset, saving visualization into %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvis_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mdataset_grid_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcycle_autoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisualize_lat_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_grid_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-038b786d298b>\u001b[0m in \u001b[0;36mcycle_autoencoder\u001b[1;34m(ae, dataset, prefix, N, vae, display)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# [z_mean, z_log_var, z] - take Z\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1645\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m     \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1037\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\anaconda3\\envs\\autoenc2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epochs in [50]:\n",
    "    for i in range(5):\n",
    "        output_suffix = \"epochs_%d-%d\" % (epochs, i)\n",
    "        trial(dataset, ae_builder, {'epochs': epochs}, output_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "robot-arm-vae2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
